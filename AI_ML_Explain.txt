
What is GenerativeModel?
Generative AI:

Generative AI refers to algorithms that can generate new content, such as text, images, music, or other types of data, based on the input they receive. Unlike traditional AI models that only classify or predict outcomes, generative models can create new data that mimics the characteristics of the training data.
GenerativeModel Class:

In your code, genai.GenerativeModel likely represents a specific implementation of a generative model designed to create text or other types of content. The model specified (e.g., 'models/gemini-1.5-flash-latest') indicates which version of the model you are using.
This class provides methods to interact with the model, such as generating content based on prompts or inputs.
How It Works
Initialization: When you create an instance of GenerativeModel, you specify the path to the model's files, which typically include the model's architecture and pre-trained weights.

Generating Content: Once you have an instance of the model, you can call methods like generate_content(...) to produce new outputs based on the inputs (prompts) you provide.

Example Usage
Real-World Example: Imagine a generative AI model like OpenAI's GPT (which is a type of generative model). When you provide a prompt (e.g., "Write a poem about autumn"), 
the model generates text that follows the style and content that you specified. Similarly, the GenerativeModel class in your code is likely doing something similar, but it may be tailored to specific applications such as generating responses related to job descriptions and resumes.

The exact functions (or methods) available for an instance of GenerativeModel from the genai library would depend on the specific implementation of the library. However, typical generative AI models, including those that you might find in libraries similar to genai, generally provide several common methods for interacting with the model.

Common Methods in Generative Models
Here are some typical methods you might find in a generative model class:

generate_content(prompt):

Description: Generates content based on the provided prompt. This is the method you used in your code snippet.
Purpose: To produce text or other outputs based on input prompts.
train(data) (if applicable):

Description: Allows the model to be fine-tuned or retrained on a specific dataset.
Purpose: To improve the model's performance on certain tasks or domains by learning from new data.
load_model(model_path):

Description: Loads a pre-trained model from a specified file path.
Purpose: To initialize the model with weights and configurations saved from a previous session.
save_model(model_path):

Description: Saves the current state of the model to a specified file path.
Purpose: To allow for later retrieval and reuse of the model.
set_parameters(params):

Description: Adjusts various parameters of the model (e.g., temperature, max length, etc.) that can affect output generation.
Purpose: To fine-tune how the model generates content.
evaluate(prompt) (if applicable):

Description: Evaluates the quality or relevance of the generated content against certain criteria.
Purpose: To assess how well the model's outputs meet the desired requirements.
How to Find Available Methods
To find out the exact methods available for the GenerativeModel in the genai library, you can do the following:

Check Documentation: If genai has official documentation, it will typically list all the available classes and their methods.

Use dir(): You can use Python’s built-in dir() function on an instance of GenerativeModel to list all attributes and methods.

python
Copy code
model = genai.GenerativeModel('models/gemini-1.5-flash-latest')
print(dir(model))
Use help(): You can also use the help() function to get more information about a specific class or method.

python
Copy code
help(model)
all function of genai libeary(generative AI)
['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', 
'__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', 
'__str__', '__subclasshook__', '__weakref__', '_async_client', '_client', '_generation_config', '_get_tools_lib', '_model_name', '_prepare_request', '_safety_settings',
 '_system_instruction', '_tool_config', 
'_tools', 'cached_content', 'count_tokens', 'count_tokens_async', 'from_cached_content', 'generate_content', 'generate_content_async', 'model_name', 'start_chat']

for generative ai first we have to create promt object in that conatin all prompt the promt can in possible in function format 

def generate_gemini_prompt(job_description: str, resume_text: str) -> str:
    prompt = f"""
Here’s the modified prompt with an example output included:

---
**Modified Prompt:**

Evaluate the following resume against the provided job description and provide a detailed evaluation in a structured JSON format. Ensure that the JSON is valid and properly formatted, with all necessary commas included.

**Job Description:** {job_description}  
**Resume:** {resume_text}

1. Extract the **email** and **phone number** from the resume.
2. Include the contact information (email and phone number) in the JSON output.
3. The JSON should be properly formatted, valid, and include all required commas and syntax.


Please include the following keys in the JSON response:

{{
  "overall_score": <numeric value between 0 and 100>,
  "relevance": <numeric score between 0 and 10>,
  "skills_fit": <numeric score between 0 and 10>,
  "experience_match": <numeric score between 0 and 10>,
  "cultural_fit": <numeric score between 0 and 10>,
  "strengths": <list of key strengths>,
  "weaknesses": <list of key weaknesses or gaps>,
  "missing_elements": <list of key missing qualifications or experiences>,
  "recommendations": <list of suggestions for improvement>
}}

### Example Output:

{{
  "overall_score": 85,
  "relevance": 9,
  "skills_fit": 8,
  "experience_match": 7,
  "cultural_fit": 6,
  "strengths": ["Strong technical skills", "Excellent communication", "Proven team player"],
  "weaknesses": ["Limited project management experience", "No certifications in relevant technologies"],
  "missing_elements": ["Experience with agile methodologies", "Leadership roles"],
  "recommendations": ["Consider obtaining project management certification", "Gain experience in agile environments"]
   "candidate_info": {{
    "name": "John Doe",
    "email": "candidate@example.com",
    "phone": "+1234567890"
}}
}}

Return the response as valid JSON format with proper commas and no syntax errors. 
"""
    return prompt

after that we have to create model object than generate_content function use 

genai.configure(api_key=os.environ["API_KEY_gm"])

prompt = generate_gemini_prompt(job_description, resume_text)
           
model = genai.GenerativeModel('models/gemini-1.5-flash-latest')
response = model.generate_content(prompt)
gemini_evaluation = response.text
######################################################################################################################################################
Using Deepface library login

in this direct during regitration direct emding code means vector code do image path than derct vrfiy using DeepFace.verify function

# Configuration for DeepFace
MODEL_NAME = "Facenet512"
BACKEND = "ssd"  # Use the detector backend you prefer

TEMP_DIRECTORY = "static/uploads/temp"
TEMP_DIRECTORY1 = "static/Driver_info_images"  # Directory for saving driver images

# Function to save uploaded files
def save_uploaded_file(file: UploadFile, directory: str) -> str:
    unique_filename = f"{uuid.uuid4()}_{file.filename}"
    file_path = os.path.join(directory, unique_filename)
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    return file_path

# Function to calculate Euclidean distance
def find_euclidean_distance(source_representation, test_representation):
    """
    Calculate the Euclidean distance between two vectors (embeddings).
    
    Args:
        source_representation (list or np.array): The source embedding.
        test_representation (list or np.array): The test embedding.
    
    Returns:
        float: The Euclidean distance between the two embeddings.
    """
    source_array = np.array(source_representation)
    test_array = np.array(test_representation)
    return np.linalg.norm(source_array - test_array)

def generate_otp():
    return random.randint(1000, 9999)

# Register a new AI surveillance user
@router.post("/register/AI_surveillance_user/")
async def register_user(
    user_name: str = Form(...),
    user_email: str = Form(...),
    user_password: str = Form(...),
    user_type: UserType = Form(UserType.user),
    phone_no: str = Form(...),
    driver_address: str = Form(...),
    driver_images: UploadFile = File(...),
    driver_license: UploadFile = File(...),
    db: Session = Depends(get_db)
):
    try:
        image_path = save_uploaded_file(driver_images, TEMP_DIRECTORY1)
        driver_license_number1 = await process_image(driver_license, "number_plate")
        driver_license_number = clean_string(driver_license_number1)
        driver_license_path = save_uploaded_file(driver_license, TEMP_DIRECTORY1)
        hashed_password = bcrypt.hashpw(user_password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
        
        # Generate face embeddings for the driver image
        embedding = DeepFace.represent(img_path=image_path, model_name=MODEL_NAME, detector_backend=BACKEND)[0]["embedding"]
        assigned_key = generate_otp()
        new_user = Surveillance_User(
            user_name=user_name, 
            driver_images=image_path,
            user_email=user_email,
            user_password=hashed_password,
            user_type=user_type,
            phone_no=phone_no,
            driver_address=driver_address,
            driver_license=driver_license_path,
            assigned_keys=assigned_key,
            embeddings=json.dumps(embedding)  # Serialize embeddings to JSON
        )
        db.add(new_user)
        db.flush()

        driver_license_db = License_info(
            user_id=new_user.user_id,
            license_number=driver_license_number
        )
        db.add(driver_license_db)
        db.commit()
        db.refresh(driver_license_db)
        
        return {"message": "User registered successfully", "username": user_name}
    
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"Registration failed: {str(e)}")

# Function to set up a temporary directory
def setup_temp_directory():
    os.makedirs(TEMP_DIRECTORY, exist_ok=True)

# Function to clean up a temporary directory
def cleanup_temp_directory():
    if os.path.exists(TEMP_DIRECTORY):
        shutil.rmtree(TEMP_DIRECTORY)
    setup_temp_directory()

# Function to log image details
def log_image_details(img_path: str):
    try:
        with Image.open(img_path) as img:
            print(f"Image format: {img.format}")
            print(f"Image size: {img.size}")
    except Exception as e:
        print(f"Error logging image details: {str(e)}")

# Identify user by comparing face embeddings
def identify_user(img_path: str, db: Session) -> Dict[str, Any]:
    try:
        # Generate the embedding for the uploaded image
        embedding_to_verify = DeepFace.represent(img_path=img_path, model_name=MODEL_NAME, detector_backend=BACKEND)[0]["embedding"]
        

        # Query all users from the database
        users = db.query(Surveillance_User).all()
        
        # Iterate through each user and compare embeddings
        for user in users:
            stored_embedding = json.loads(user.embeddings)  # Deserialize embeddings from JSON
            distance = find_euclidean_distance(stored_embedding, embedding_to_verify)
            print(f"Comparing with user {user.user_name}: distance = {distance}")

            if distance < 15:  # Adjust this threshold as needed
                return {"message": "Login successful", "user": user}

        # Raise 404 error if no match is found
        raise HTTPException(status_code=404, detail="No matching face found")
    
    except Exception as e:
        print(f"Error identifying user: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {str(e)}")
    finally:
        cleanup_temp_directory()



# Default dimensions for resizing
DEFAULT_WIDTH = 738
DEFAULT_HEIGHT = 991
DEFAULT_BRIGHTNESS = 1.0  # Default brightness (1.0 = no change)
DEFAULT_EXT = ".jpg"  # Default file extension
import logging
def preprocess_image(image_path: str) -> str:
    """Resize the image and adjust lighting before identification, saving with a default extension."""
    with Image.open(image_path) as img:
        # Resize the image to the default dimensions
        img = img.resize((DEFAULT_WIDTH, DEFAULT_HEIGHT))

        # Adjust the lighting (brightness)
        enhancer = ImageEnhance.Brightness(img)
        img = enhancer.enhance(DEFAULT_BRIGHTNESS)

        # Prepare the path for the preprocessed image with a default extension
        base_name = os.path.splitext(os.path.basename(image_path))[0]
        preprocessed_image_path = os.path.join(TEMP_DIRECTORY, f"preprocessed_{base_name}{DEFAULT_EXT}")

        # Save the preprocessed image as JPEG
        img.save(preprocessed_image_path, format='JPEG')
        
        logging.info(f"Preprocessed image saved at: {preprocessed_image_path}")
    
    return preprocessed_image_path



# AI Surveillance login route
@router.post("/AI_surveillance_login/")
async def login_user(
    file: Optional[UploadFile] = File(None),
    user_email: Optional[str] = Form(None),
    user_password: Optional[str] = Form(None),
    db: Session = Depends(get_db)
) -> Dict[str, Any]:
    try:
        if file:
            setup_temp_directory()
            uploaded_image_path = save_uploaded_file(file, TEMP_DIRECTORY)
            print(f"Uploaded image path: {uploaded_image_path}")
            
            # Preprocess the image (resize and adjust lighting)
            preprocessed_image_path = preprocess_image(uploaded_image_path)
            print(f"Preprocessed image path: {preprocessed_image_path}")
            # Log image details
            log_image_details(uploaded_image_path)

            identification_result = identify_user(img_path=uploaded_image_path, db=db)
            if "error" in identification_result:
                raise HTTPException(status_code=500, detail=identification_result["error"])
            
            user = identification_result.get("user")
        elif user_email and user_password:
            user = db.query(Surveillance_User).filter(Surveillance_User.user_email == user_email).first()
            if not user:
                raise HTTPException(status_code=404, detail="User not found")

            if not bcrypt.checkpw(user_password.encode('utf-8'), user.user_password.encode('utf-8')):
                raise HTTPException(status_code=401, detail="Invalid credentials")
        else:
            raise HTTPException(status_code=400, detail="Please provide either an image or both email and password")

        token, exp = signJWT(user.user_id, user.user_type)
        Vehicle_number = db.query(Vehicle_info).filter(
            Vehicle_info.user_id == user.user_id, 
            
        ).first()
        
        response = {
            "message": "Login successful",
            "token": token,
            "exp": exp,
            "user_id": user.user_id,
            "user_name": user.user_name,
            "email_id": user.user_email,
            "user_type": user.user_type,
            "created_on": user.created_on.isoformat(),
            "phone_no": user.phone_no,
            "driver_address": user.driver_address,
            "assigned_keys": user.assigned_keys if user.assigned_keys else None,
            "Truck_number": Vehicle_number.truck_number if Vehicle_number  else None
        }
        
        return response

    except HTTPException as e:
        print(f"HTTPException: {str(e)}")
        raise e
    except Exception as e:
        print(f"Exception: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Login failed: {str(e)}")
    finally:
        cleanup_temp_directory()

#################################################################################################
# in this first fetch path from databse if path match than get user id from path than emding path than verify

def setup_temp_directory():
    if not os.path.exists(TEMP_DIRECTORY):
        os.makedirs(TEMP_DIRECTORY)

def cleanup_temp_directory():
    if os.path.exists(TEMP_DIRECTORY):
        shutil.rmtree(TEMP_DIRECTORY)
    setup_temp_directory()

def save_uploaded_file(file: UploadFile) -> str:
    unique_filename = f"{uuid.uuid4()}_{file.filename}"
    file_path = os.path.join(TEMP_DIRECTORY, unique_filename)
    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    return file_path

def identify_user(img_path: str, db: Session) -> Dict[str, Any]:
    try:
        users = db.query(Surveillance_User).all()
        if not users:
            return {"message": "No users found in the database."}

        user_image_map = {}
        for user in users:
            if os.path.exists(user.driver_images):
                temp_image_path = os.path.join(TEMP_DIRECTORY, f"{uuid.uuid4()}.jpg")
                shutil.copy(user.driver_images, temp_image_path)
                user_image_map[temp_image_path] = user.user_id

        df = DeepFace.find(img_path=img_path, db_path=TEMP_DIRECTORY,
                           model_name=MODEL_NAME, detector_backend=BACKEND,
                           distance_metric="euclidean_l2", enforce_detection=False)
        
        if isinstance(df, list) and df:
            matched_image_path = df[0]['identity'][0]
            user_id = user_image_map.get(matched_image_path)
            
            if user_id:
                user = db.query(Surveillance_User).filter(Surveillance_User.user_id == user_id).first()
                
                if user:
                    result = DeepFace.verify(img1_path=img_path, img2_path=matched_image_path,
                                             model_name=MODEL_NAME, detector_backend=BACKEND,
                                             enforce_detection=False)
                    
                    if result["verified"]:
                        return {"user": user, "message": "Login successful"}
                    else:
                        return {"message": "Login failed. Face verification did not match."}
                else:
                    return {"message": "User not found in the database."}
            else:
                return {"message": "No matching user found for the recognized face."}
        else:
            return {"message": "No matching face found."}
    
    except Exception as e:
        return {"error": str(e)}
    finally:
        cleanup_temp_directory()

@router.post("/AI_surveillance_login/")
async def login_user(
    file: Optional[UploadFile] = File(None),
    user_email: Optional[str] = Form(None),
    user_password: Optional[str] = Form(None),
    db: Session = Depends(get_db)
) -> Dict[str, Any]:
    try:
        if file:
            setup_temp_directory()
            uploaded_image_path = save_uploaded_file(file)
            identification_result = identify_user(img_path=uploaded_image_path, db=db)
            
            if "error" in identification_result:
                raise HTTPException(status_code=500, detail=f"Error during face recognition: {identification_result['error']}")
            
            if "user" in identification_result:
                user = identification_result["user"]
            else:
                return identification_result
        elif user_email and user_password:
            user = db.query(Surveillance_User).filter(Surveillance_User.user_email == user_email).first()
            if not user:
                raise HTTPException(status_code=404, detail=f"Record with Email: {user_email} not found")
            
            if user.user_password is None:
                raise HTTPException(status_code=400, detail="User password is not set")

            if not bcrypt.checkpw(user_password.encode('utf-8'), user.user_password.encode('utf-8')):
                raise HTTPException(status_code=401, detail="Invalid credentials")
        else:
            raise HTTPException(status_code=400, detail="Please provide either an image or both email and password")

        token, exp = signJWT(user.user_id, user.user_type)
        assigned_key = db.query(Key_Asigned).filter(
            Key_Asigned.user_id == user.user_id, 
            Key_Asigned.is_assign_course == True
        ).first()
        
        response = {
            "message": "Login successful",
            "token": token,
            "exp": exp,
            "user_id": user.user_id,
            "user_name": user.user_name,
            "email_id": user.user_email,
            "user_type": user.user_type,
            "created_on": user.created_on.isoformat(),
            "phone_no": user.phone_no,
            "driver_address": user.driver_address,
            "assigned_keys": assigned_key.vehicle_key if assigned_key else None,
            "Truck_number": assigned_key.truck_number if assigned_key else None
        }
        
        return response

    except HTTPException as e:
        raise e
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Login failed: {str(e)}")
    finally:
        cleanup_temp_directory()

####################    Using Geni api do OCR #########################


def save_upload(upload_file: Optional[UploadFile]) -> Optional[str]:
    if not upload_file:
        return None
    
    try:
        unique_filename = f"{uuid.uuid4()}_{upload_file.filename}"
        file_path = os.path.join("static", "arrival_images", unique_filename)
        
        os.makedirs(os.path.dirname(file_path), exist_ok=True)

        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(upload_file.file, buffer)
        
        return file_path.replace("\\", "/")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error saving file: {str(e)}")

# Configure the Google API key
genai.configure(api_key="AIzaSyBu09u-HqAT7z0_ztXu5gxjNnGA7I1oQDY")

CUSTOM_PROMPTS = {
    "number_plate": 'Extract the number plate from the provided image of a truck. Return the result in a JSON format with the key "number_plate" and the value as the extracted number plate. If the number plate cannot be identified, return null for the value.',
    "driving_license": 'Extract the driving license number from the provided image of a driving license. Return the result in a JSON format with the key "driving_license_number" and the value as the extracted number. If the number cannot be identified, return null for the value.',
    "chassis": 'Extract the chassis number from the provided image of a vehicle. Return the result in a JSON format with the key "chassis_number" and the value as the extracted number. If the number cannot be identified, return null for the value.'
}


async def process_image(image_file: UploadFile, prompt_key: str):
    if image_file.content_type not in ["image/jpeg", "image/png"]:
        raise HTTPException(status_code=400, detail="Invalid file type. Please upload a jpg, jpeg, or png image.")
    
    image_data = await image_file.read()
    image = Image.open(io.BytesIO(image_data))
    
    model = genai.GenerativeModel(model_name="models/gemini-1.5-flash")
    result = model.generate_content([CUSTOM_PROMPTS[prompt_key], image])
    
    try:
        # Remove code block markers if present
        clean_text = re.sub(r'```json\s*|\s*```', '', result.text)
        json_result = json.loads(clean_text)
        return json_result.get(prompt_key) or json_result.get("number_plate") or json_result.get("chassis_number")
    except json.JSONDecodeError:
        logging.error(f"Failed to parse JSON from Gemini AI response: {result.text}")
        return None
    
def clean_string(input_str: str) -> str:
    # Use regex to remove spaces and special characters, only keeping alphanumeric characters
    return re.sub(r'[^A-Za-z0-9]', '', input_str)

@router.post("/arrival/")
async def arrival(
    vehicle_number: UploadFile = File(...), 
    chassis: UploadFile = File(...),
    condition: UploadFile = File(...),
    license_image: UploadFile = File(...),
    Container_image: UploadFile = File(...),
    db:Session= Depends(get_db)):

    try:
        vehicle_number_text1 = await process_image(vehicle_number, "number_plate")
        vehicle_number_text = clean_string(vehicle_number_text1)
        chassis_number_text = await process_image(chassis, "chassis")
        license_image_Text1 = await process_image(license_image, "number_plate")
        license_image_Text = clean_string(license_image_Text1)
    
        condition_url = save_upload(condition)
        container_image_url = save_upload(Container_image)
    
        print('vehicle_number_text',vehicle_number_text)
        Vehicle_info_data = db.query(Vehicle_info).filter(Vehicle_info.truck_number == vehicle_number_text).first()
        if not Vehicle_info_data:
            raise HTTPException(status_code=404, detail="truck_number  not matched")

        license_image_data = db.query(License_info).filter(License_info.license_number == license_image_Text).first()
        
        if not license_image_data:
            raise HTTPException(status_code=404, detail="Driver license not matched")
        
        arrival_db=Arrival(
            vehicle_number =vehicle_number_text,
            chassis = chassis_number_text, 
            condition = condition_url,
            license_image = license_image_Text,
            Container_image =container_image_url,

        )
        db.add(arrival_db)
        db.commit()
        db.refresh(arrival_db)

        return {
             'message':'now you can u go',
            'arrival_data ':arrival_db, 
            
        }
    except Exception as e:
        logging.error(f"Error processing the image: {e}")
        raise HTTPException(status_code=500, detail=str(e))













